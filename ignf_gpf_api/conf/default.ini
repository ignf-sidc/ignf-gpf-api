[logging]
# Niveaux de log expliqués ici : https://docs.python.org/2/library/logging.html#logging-levels
# 10 DEBUG 20 INFO 30 WARNING 40 ERROR 50 CRITICAL
log_level=20

[store_authentification]
############################### Paramétrage de l'authentification via KeyCloack ###############################
token_url=https://qlf-iam-gpf.ign.fr/auth/realms/master/protocol/openid-connect/token
login=LOGIN_TO_MODIFY
password=PASSWORD_TO_MODIFY
client_id=guichet
# En cas d'échec lors de l'authentification : max nb_attempts tentatives, sec_between_attempt secondes entre chacune d'entre elle
nb_attempts=5
sec_between_attempt=1

[store_api]
############################### Routes de l'API Entrepôt ###############################
root_url=https://api-qualification.ccs-ign-plage.ccs.cegedim.cloud/api/v1
datastore=DATASTORE_ID_TO_MODIFY
root_datastore=%(root_url)s/datastores/%(datastore)s
########## Routes/Uploads
# Cette route est suffixée par Upload.list avec les filtres sur les propriétés de livraison : ?param_name=param_value&param2_name=param2_value
# et avec les filtres sur les tags de livraison (pattern road_uploads_list_tag_suffix ci-dessous)
road_uploads_list=%(root_datastore)s/uploads
road_upload_read_infos_one=%(road_uploads_list)s/{upload}
road_upload_read_tree_one=%(road_upload_read_infos_one)s/tree
road_uploads_list_property_suffix={property_name}={property_value}
road_uploads_list_tag_suffix=tags[]={tag_name}={tag_value}
road_upload_delete=%(root_datastore)s/uploads/{upload}
road_upload_checks=%(road_upload_read_infos_one)s/checks

# Création d'upload
road_upload_creation=%(root_datastore)s/uploads
road_upload_add_tags=%(road_upload_read_infos_one)s/tags
road_upload_push_data=%(road_upload_read_infos_one)s/data
road_upload_push_metadata=%(road_upload_read_infos_one)s/metadata
road_upload_push_attachment=%(road_upload_read_infos_one)s/annexes
road_upload_push_md5=%(road_upload_read_infos_one)s/md5
road_upload_close=%(road_upload_read_infos_one)s/close

########## Routes/StoredDatas
# Cette route est suffixée par StoredData.list avec les filtres sur les propriétés de livraison : ?param_name=param_value&param2_name=param2_value
# et avec les filtres sur les tags de livraison (pattern road_stored_datas_list_tag_suffix ci-dessous)
road_stored_datas_list=%(root_datastore)s/stored_data
road_stored_data_read_infos_one=%(road_stored_datas_list)s/{stored_data}
road_stored_datas_list_property_suffix={property_name}={property_value}
road_stored_datas_list_tag_suffix=tags[]={tag_name}={tag_value}

########## Routes/Checks
road_available_checks=%(root_datastore)s/checks
road_check_log=%(road_available_checks)s/executions/{execution}/logs

########## Routes/Processings
road_available_processings=%(root_datastore)s/processings
road_processing-execution_creation=%(road_available_processings)s/executions
road_processing-execution_read=%(road_processing-execution_creation)s/{execution}
road_processing-execution_launch=%(road_processing-execution_read)s/launch
road_processing-execution_delete=%(road_processing-execution_read)s
road_processing-execution_logs=%(road_processing-execution_read)s/logs
nb_sec_between_log_updates=10

############################### Contrainte d'unicité à la création d'une livraison ###############################
# Contrainte d'unicité définie par un ensemble de propriétés ET de tags (laisser vide si aucune). Les propriétés d'une même ligne sont séparées par un point-virgule
# Exemple : pour définir une unicité sur name, srs et dpsg indiquer uniqueness_constraint_upload_infos=name;srs ET uniqueness_constraint_tags=dpsg
uniqueness_constraint_upload_infos=name
uniqueness_constraint_tags=dpsg
# Comportement du programme bagi_creation_livraison si une livraison existe déjà (sur la base de la contrainte d'unicité)
# DELETE : tente de supprimer la livraison existante, STOP : le programme affiche uniquement un message et s'arrête
behavior_if_exists=DELETE

[json_schemas]
############################### Schémas de validation ###############################
# Les chemins sont définis relativement à bin/bagi_*.py programs
descriptor_file=../conf/json_schemas/upload_descriptor_file_ign.json
workflow_config=../conf/json_schemas/workflow_config.json

[upload_creation]
# Paramètre générique permettant de définir le chemin du fichier descripteur de livraison (paramètre court, paramètre long, descriptif, exemple)
generic_parameter_for_upload_path=-d,--dpsg,Identifiant de la dpsg concernée par la livraison à créer,dpsg2017-02-00028
# Chemin vers le fichier descripteur défini à partir du paramètre générique (définir à "{generic_parameter_for_upload_path}" si ce paramètre contient directement le chemin)
upload_descriptor_file_path={generic_parameter_for_upload_path}/desc_file_{generic_parameter_for_upload_path}.json

[miscellaneous]
# Répertoire contenant les données sur l'entrepôt
data_directory_on_store=data/
ISOAP_metadata_directory_on_store=metadata/ISOAP/
INSPIRE_metadata_directory_on_store=metadata/INSPIRE/
# Répertoire existant disposant de droits en écriture (fichiers très temporaires) avec un slash à la fin
tmp_workdir=/tmp/

# Regex filtrant les fichiers de métadonnées à téléverser
regex_metadata_file_to_upload=^.*\.xml$

# Type de back-office activé
back_office_type=SiteBO,QuiDoncBO

[workflow_description]
# Classe de lecture du workflow
workflow_reader=FileWorkflowReader
# Liste des paramètres génériques de bagi_preparation_donnees.
# Elle est définie de façon générique (pour l'IGN, on utilise les codes dpsg). Les paramètres sont séparés par un point-virgule.
# Les trois chaines de caractères séparées par une virgule correspondent aux trois paramètres de parser.add_argument de bagi_preparation_donnees
# Exemple : -d, --dpsg, description param dpsg;-p, --param2, description param2
generic_parameters=-d,--dpsg, Identifiant de la dpsg concernée par le traitement d alimentation

[workflow_resolution_regex]
# store_entity_regex permet la designation d une balise à résoudre de type storeentity
# Exemple de balise : {storeentity.upload.tags.edition[INFOS(name=toto), TAG(dpsg={param.dpsg}, type=validation)]}

# les multiplicateurs * sont suivis de ? de façon à prendre les chaînes les plus petites possibles
# Les groupes sont nommés de façon à pouvoir extraire facilement les infos. Voici les groupes :
# groupe entity_type : type d'entité sur l'entrepôt (upload...)
# groupe selected_field_type : type de champ requêté (info ou tag) sur l'entité entrepôt
# groupe filter_infos : filtre sur les informations d'une entité de l'entrepôt
# groupe filter_tags : filtre sur une entité entrepôt exploitant ses tags

# Filtre de storeentity à partir des propriétés
filter_infos = ((\s*)INFOS(\s*)\((?P<filter_infos>.*?)\)(\s*))?
# Filtre de storeentity à partir des tags
filter_tags   = ((\s*)TAGS(\s*)\((?P<filter_tags>.*?)\)(\s*))?
filter = ((\s*)\[%(filter_infos)s,?%(filter_tags)s\])
store_entity_regex=(?P<all>\{(store_entity\.)(?P<entity_type>(upload|stored_data|processing-execution|offering|resource))\.(?P<selected_field_type>(tags|infos))\.(?P<selected_field>\w*)%(filter)s\})

[test_dataset]
