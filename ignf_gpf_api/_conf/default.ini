[logging]
# Niveaux de log expliqués ici : https://docs.python.org/2/library/logging.html#logging-levels
# DEBUG, INFO, WARNING, ERROR, CRITICAL
log_level=INFO


[store_authentification]
############################### Paramétrage de l'authentification via KeyCloak ###############################
token_url=https://qlf-iam-gpf.ign.fr/auth/realms/master/protocol/openid-connect/token
login=LOGIN_TO_MODIFY
password=PASSWORD_TO_MODIFY
client_id=CLIENT_ID_TO_MODIFY
# En cas d'échec lors de l'authentification : max nb_attempts tentatives, sec_between_attempt secondes entre chacune d'entre elles
nb_attempts=5
sec_between_attempt=1


[store_api]
############################### Paramètres de l'API Entrepôt ###############################
root_url=https://api-qualification.ccs-ign-plage.ccs.cegedim.cloud/api/v1
datastore=DATASTORE_ID_TO_MODIFY
root_datastore=${store_api:root_url}/datastores/${store_api:datastore}
# En cas d'échec lors du requêtage : max nb_attempts tentatives, sec_between_attempt secondes entre chacune d'entre elles
nb_attempts=5
sec_between_attempt=1
# Nb max d'éléments à récupérer en cas de listing
nb_limit=10
# Regex de parsing du Content-Range des réponses
regex_content_range=(?P<i_min>[0-9]+)-(?P<i_max>[0-9]+)/(?P<len>[0-9]+)


[routing]
############################### Routes de l'API Entrepôt ###############################
# User
user_get=${store_api:root_url}/users/me
# Datastore
datastore_get=${store_api:root_datastore}

# Upload
upload_list=${store_api:root_datastore}/uploads
upload_create=${routing:upload_list}
upload_get=${routing:upload_list}/{upload}
upload_delete=${routing:upload_list}/{upload}
upload_add_tags=${upload_get}/tags
upload_delete_tags=${upload_get}/tags
upload_push_data=${upload_get}/data
upload_delete_data=${upload_push_data}
upload_push_md5=${upload_get}/md5
upload_delete_md5=${upload_push_md5}
upload_close=${upload_get}/close
upload_open=${upload_get}/open
upload_tree=${upload_get}/tree
upload_list_checks=${upload_get}/checks
upload_run_checks=${upload_get}/checks
upload_list_comment=${upload_get}/comments
upload_add_comment=${upload_list_comment}
upload_edit_comment=${upload_list_comment}/{comment}
upload_remove_comment=${upload_list_comment}/{comment}
upload_list_sharings=${upload_get}/sharings
upload_add_sharing=${upload_list_sharings}
upload_remove_sharing=${upload_list_sharings}
upload_list_events=${upload_get}/events

# StoredData
stored_data_list=${store_api:root_datastore}/stored_data
stored_data_get=${stored_data_list}/{stored_data}
stored_data_delete=${stored_data_list}/{stored_data}
stored_data_add_tags=${stored_data_get}/tags
stored_data_delete_tags=${stored_data_get}/tags
stored_data_list_comment=${stored_data_get}/comments
stored_data_add_comment=${stored_data_list_comment}
stored_data_edit_comment=${stored_data_list_comment}/{comment}
stored_data_remove_comment=${stored_data_list_comment}/{comment}
stored_data_list_sharings=${stored_data_get}/sharings
stored_data_add_sharing=${stored_data_list_sharings}
stored_data_remove_sharing=${stored_data_list_sharings}
stored_data_list_events=${stored_data_get}/events

# Processing
processing_list=${store_api:root_datastore}/processings
processing_get=${processing_list}/{processing}

# Processing Execution
processing_execution_list=${processing_list}/executions
processing_execution_create=${processing_execution_list}
processing_execution_get=${processing_execution_list}/{processing_execution}
processing_execution_delete=${processing_execution_get}
processing_execution_launch=${processing_execution_get}/launch
processing_execution_abort=${processing_execution_get}/abort
processing_execution_logs=${processing_execution_get}/logs

# Configuration
configuration_list=${store_api:root_datastore}/configurations
configuration_get=${configuration_list}/{configuration}
configuration_create=${configuration_list}
configuration_delete=${configuration_get}
configuration_put=${configuration_get}
configuration_add_tags=${configuration_get}/tags
configuration_delete_tags=${configuration_get}/tags
configuration_list_comment=${configuration_get}/comments
configuration_add_comment=${configuration_list_comment}
configuration_edit_comment=${configuration_list_comment}/{comment}
configuration_remove_comment=${configuration_list_comment}/{comment}
configuration_list_offerings=${configuration_get}/offerings

# Offering
offering_list=${store_api:root_datastore}/offerings
offering_get=${offering_list}/{offering}
offering_create=${configuration_list_offerings}
offering_delete=${offering_get}
offering_patch=${offering_get}

# Check
check_list=${store_api:root_datastore}/checks
check_get=${routing:check_list}/{check}

# CheckExecution
check_execution_list=${routing:check_list}/executions
check_execution_get=${routing:check_execution_list}/{check_execution}
check_execution_delete=${routing:check_execution_list}/{check_execution}
check_execution_logs=${routing:check_execution_get}/logs


[upload_creation]
############################### Contrainte d'unicité à la création d'une livraison ###############################
# Contrainte d'unicité définie par un ensemble de propriétés ET de tags (laisser vide si aucune). Les propriétés
# d'une même ligne sont séparées par un point-virgule
# Exemple :
# pour définir une unicité sur les attributs "name", "srs" et le tag "livraison"
# indiquez uniqueness_constraint_infos=name;srs ET uniqueness_constraint_tags=livraison
uniqueness_constraint_infos=name
uniqueness_constraint_tags=
# Comportement du programmesi une livraison existe déjà (sur la base de la contrainte d'unicité)
#   - DELETE : tente de supprimer la livraison existante et de la recréer,
#   - CONTINUE : le programme reprend le transfert
#   - STOP : le programme affiche uniquement un message et s'arrête
behavior_if_exists=STOP
md5_pattern={md5_key}  data/{file_path}
push_data_file_key=filename
push_md5_file_key=filename
nb_sec_between_check_updates=10
check_message_pattern=Vérifications : {nb_asked} en attente, {nb_in_progress} en cours, {nb_failed} en échec, {nb_passed} en succès

[upload_status]
open_status=OPEN
close_status=CLOSE

[processing_execution]
nb_sec_between_check_updates=10
# Contrainte d'unicité définie par un ensemble de propriétés ET de tags (laisser vide si aucune). Les propriétés
# d'une même ligne sont séparées par un point-virgule
uniqueness_constraint_infos=name
uniqueness_constraint_tags=
# Comportement du programme si une donnée stockée en sortie d'une exécution de traitement existe déjà (sur la base de la contrainte d'unicité)
#   - DELETE : tente de supprimer la donnée stockée et l'exécution de traitement existantes puis de les recréer,
#   - STOP : le programme affiche uniquement un message et s'arrête
behavior_if_exists=STOP

[miscellaneous]
# Répertoire contenant les données sur l'entrepôt
data_directory_on_store=data
# Répertoire local et existant disposant de droits en écriture (fichiers temporaires)
tmp_workdir=/tmp


[workflow_resolution_regex]
# store_entity_regex permet la designation d une balise à résoudre de type storeentity
# Exemple de balise : {storeentity.upload.tags.edition[INFOS(name=toto), TAG(dpsg={param.dpsg}, type=validation)]}

# les multiplicateurs * sont suivis de ? de façon à prendre les chaînes les plus petites possibles
# Les groupes sont nommés de façon à pouvoir extraire facilement les infos. Voici les groupes :
#   - groupe entity_type : type d'entité sur l'entrepôt (upload...)
#   - groupe selected_field_type : type de champ requêté (info ou tag) sur l'entité entrepôt
#   - groupe filter_infos : filtre sur les informations d'une entité de l'entrepôt
#   - groupe filter_tags : filtre sur une entité entrepôt exploitant ses tags

# Filtre de store_entity à partir des propriétés
filter_infos = ((\s*)INFOS(\s*)\((?P<filter_infos>.*?)\)(\s*))?
# Filtre de store_entity à partir des tags
filter_tags = ((\s*)TAGS(\s*)\((?P<filter_tags>.*?)\)(\s*))?
filter = ((\s*)\[${filter_infos},?${filter_tags}\])
store_entity_regex=(?P<entity_type>(upload|stored_data|processing_execution|offering|processing|configuration|endpoint))\.(?P<selected_field_type>(tags|infos))\.(?P<selected_field>\w*)${filter}
global_regex=(?P<param>{(?P<resolver_name>[a-z_]+)\.(?P<to_solve>.*)})
file_regex=(?P<resolver_type>str|list|dict)\((?P<resolver_file>.*)\)


[json_converter]
# Pattern de convertion des types Python en str
datetime_pattern = %Y-%m-%dT%H:%M:%S
date_pattern = %Y-%m-%d
time_pattern = %H:%M:%S


[json_schemas]
# Les chemins sont définis relativement à ignf_gpf_api/conf
descriptor_file=json_schemas/upload_descriptor_file.json
workflow_config=json_schemas/workflow_config.json
